{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aMWnmv0lXHO"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/CristianR8/Imagenes-Espectrales-Sesion4-Parte1-HoCV/main/images/banner-spectral.png\" width=\"1000\" align=\"middle\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLRNRbhzzxUu"
      },
      "source": [
        "\n",
        "# <font color='#ECA702'>**Hands-on Sesi칩n 4: Clasificacion espectral 游닞 游깯**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpzOWtyo3uf7"
      },
      "source": [
        "# <font color='#4C5FDA'>**Objetivo**</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcaIYiXr39TU"
      },
      "source": [
        "El objetivo de la clasificaci칩n hiperespectral es clasificar cada p칤xel/punto de datos en una de $K$ clases.  En general, los m칠todos de clasificaci칩n son m치s eficaces que los de desmezcla hiperespectral. Sin embargo, los m칠todos de clasificaci칩n no son eficaces a la hora de determinar las cantidades de proporci칩n subp칤xel o la cantidad de un material que puede encontrarse dentro del campo de visi칩n correspondiente a un p칤xel.  \n",
        "\n",
        "En general, los enfoques de clasificaci칩n hiperespectral implican:\n",
        "1. (opcionalmente) extracci칩n de caracter칤sticas\n",
        "2. aplicaci칩n de un clasificador est치ndar (es decir, clasificadores de la bibliograf칤a sobre aprendizaje autom치tico).\n",
        "\n",
        "Para esta sesi칩n haremos uso de 3 clasificadores comunes segun el estado del arte en la clasificacion espectral de im치genes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6CXO95ZyjkX"
      },
      "source": [
        "# <font color='#4C5FDA'>**Explicaci칩n m칠tricas empleadas**</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBmD07AFyjkZ"
      },
      "source": [
        "- Precisi칩n (Accuracy): La precisi칩n es probablemente la m칠trica m치s directa y sencilla para entender. Imagina que tienes un conjunto de im치genes y un clasificador que intenta identificar si cada imagen contiene o no un perro. Si el clasificador eval칰a 100 im치genes y acierta (correctamente identifica si hay o no un perro) en 90 de ellas, entonces la precisi칩n del clasificador es del 90%. En t칠rminos matem치ticos, la precisi칩n se calcula como el n칰mero de predicciones correctas (tanto positivas como negativas) dividido por el n칰mero total de predicciones hechas. Se puede expresar como:\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "  <img src=\"https://raw.githubusercontent.com/CristianR8/Imagenes-Espectrales-Sesion4-Parte1-HoCV/main/images/accuracy.png\" alt=\"Imagenes espectrales\" style=\"width: 400px;\"/>\n",
        "</div>\n",
        "\n",
        "- 칈ndice de Jaccard: El 칤ndice de Jaccard, tambi칠n conocido como la Intersecci칩n sobre la Uni칩n (IoU), es una medida un poco m치s sofisticada que se usa especialmente para evaluar la calidad de los clasificadores en tareas de segmentaci칩n de im치genes, donde no solo importa saber si una imagen contiene un objeto espec칤fico, sino tambi칠n d칩nde est치 ese objeto dentro de la imagen.  Se calcula como la intersecci칩n (el 치rea que ambos rect치ngulos, el predicho y el verdadero, comparten) dividida por la uni칩n (el 치rea total cubierta por ambos rect치ngulos, sin contar dos veces las 치reas que se superponen). Esto se expresa matem치ticamente como:\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "  <img src=\"https://raw.githubusercontent.com/CristianR8/Imagenes-Espectrales-Sesion4-Parte1-HoCV/main/images/jaccard.webp\" alt=\"Imagenes espectrales\" style=\"width: 400px;\"/>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUkJ3TPRyjka"
      },
      "source": [
        "**Al finalizar este Notebook deberas obtener una grafica comparativa con las predicciones de los tres clasificadores propuestos**\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "  <img src=\"https://raw.githubusercontent.com/CristianR8/Imagenes-Espectrales-Sesion4-Parte1-HoCV/main/images/objetivo.png\" alt=\"Imagenes espectrales\" style=\"width: 700px;\"/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU0q6r7myjkb"
      },
      "source": [
        "# <font color='#4C5FDA'>**Importamos datos necesarios**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HQou0Fz0yjkc"
      },
      "outputs": [],
      "source": [
        "# NO MODIFIQUES ESTA CELDA\n",
        "%%capture\n",
        "!pip install gdown\n",
        "!gdown --id 1ob4CwfeG-g2PWaxJdnmFnF4gB0e9Dd8d #PaviaU_gt.mat\n",
        "!gdown --id 1ZjpMKaMTSLbM4x3XpMCpootVjkLiFWde #PaviaU.mat\n",
        "!gdown --id 13X3I26JniCKag4DTrXF6d8f3xBs2o7Td #QPP.py\n",
        "!gdown --id 14BTtiRg0BEP30PBULLUQ-NWG3ydmsyyH #SPICE.py\n",
        "!gdown --id 1XP2gip7PFl04ojFoAsWaJ9hdeCFXfU9Y #cnn_x_test.pth\n",
        "!gdown --id 14kwBxZOU1ttYacU0P37bgRK8cXcM7tOB #cnn_x_train.pth\n",
        "!gdown --id 1zXFhgjAbN38P1sZxOTTEnpaj72ZKQmx4 #cnn_y_test.pth\n",
        "!gdown --id 14rAst2xEdoAeT5M-JZOGrlx2piAjmV67 #cnn_y_train.pth\n",
        "!gdown --id 1gxVjW0v-1e11-iGUfQHdmpjvkWtb4nie #model_pca.pkl\n",
        "!gdown --id 1vXEziBRgej4-PFYn5b5aQhMchLZZtOdb #complete_model.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihjoJFVnFtHm"
      },
      "source": [
        "# <font color='#4C5FDA'>**Importamos librerias**</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1ZjpMKaMTSLbM4x3XpMCpootVjkLiFWde #PaviaU.mat"
      ],
      "metadata": {
        "id": "qoVAfGZvyW6A",
        "outputId": "ed725b6f-0d08-440a-ba0e-a16948082b07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Failed to retrieve file url:\n",
            "\n",
            "\tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses.\n",
            "\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=1ZjpMKaMTSLbM4x3XpMCpootVjkLiFWde\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-UV64zD5pGdU"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install earthpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0f-uPpbmFpO2"
      },
      "outputs": [],
      "source": [
        "from scipy.io import loadmat\n",
        "import earthpy.spatial as es\n",
        "import earthpy.plot as epp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import joblib\n",
        "import seaborn as sns\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import matplotlib.colors as mcolors\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, jaccard_score\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "\n",
        "\n",
        "sns.set()\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzR77eFUecxL"
      },
      "source": [
        "## <font color='#4C5FDA'>**Informaci칩n del Dataset**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rPiTRY4eZAV"
      },
      "source": [
        "El conjunto de datos de la Universidad de Pav칤a es un conjunto de datos de im치genes hiperespectrales recogidas por un sensor conocido como espectr칩metro de im치genes de sistema 칩ptico reflectante (ROSIS-3) sobre la ciudad de Pav칤a, Italia. La imagen consta de 610칑340 p칤xeles con 115 bandas espectrales. La imagen se divide en 9 clases con un total de 42.776 muestras etiquetadas, entre las que se incluyen el asfalto, los prados, la grava, los 치rboles, la chapa met치lica, el suelo desnudo, el bet칰n, el ladrillo y la sombra.\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "  <img src=\"https://raw.githubusercontent.com/CristianR8/Imagenes-Espectrales-Sesion4-Parte1-HoCV/main/images/paviau.jpg\" alt=\"Imagenes espectrales\" style=\"width: 600px;\"/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW-91xCJeM7y"
      },
      "source": [
        "# <font color='#4C5FDA'><small>**Cargamos el conjunto de datos**</small></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "_pYyByS52xTO",
        "outputId": "82aa6796-6ecb-493a-f3ae-28c4df4023b4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'PaviaU.mat'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/io/matlab/_mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'PaviaU.mat'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ba4108e51807>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'PaviaU.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mground_truth_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'PaviaU_gt.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_paviau_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Visualizar la primera banda de la imagen y la verdad fundamental para verificar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-ba4108e51807>\u001b[0m in \u001b[0;36mload_paviau_dataset\u001b[0;34m(data_path, ground_truth_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_paviau_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground_truth_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/io/matlab/_mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, spmatrix, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \"\"\"\n\u001b[1;32m    232\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/io/matlab/_mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/io/matlab/_mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             raise OSError(\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'PaviaU.mat'"
          ]
        }
      ],
      "source": [
        "def load_paviau_dataset(data_path, ground_truth_path):\n",
        "\n",
        "    data = loadmat(data_path)\n",
        "    gt = loadmat(ground_truth_path)\n",
        "\n",
        "    # Assuming the variable names in the .mat files are 'paviaU' and 'paviaU_gt' respectively.\n",
        "    # Adjust the keys if they are different in your dataset files.\n",
        "    img = data['paviaU']\n",
        "    gt = gt['paviaU_gt']\n",
        "\n",
        "    return img, gt\n",
        "\n",
        "# Funcion de preprocesamiento\n",
        "def preprocess_data(img, gt):\n",
        "    n_rows, n_cols, n_bands = img.shape\n",
        "    pixels = img.reshape((n_rows*n_cols, n_bands))\n",
        "    labels = gt.ravel()\n",
        "    return pixels, labels\n",
        "\n",
        "# Ejemplo de uso\n",
        "data_path = 'PaviaU.mat'\n",
        "ground_truth_path = 'PaviaU_gt.mat'\n",
        "img, gt = load_paviau_dataset(data_path, ground_truth_path)\n",
        "\n",
        "# Visualizar la primera banda de la imagen y la verdad fundamental para verificar\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(img[:, :, 0], cmap='gray')\n",
        "plt.title('First Band of Hyperspectral Image')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(gt, cmap='jet')\n",
        "plt.title('Ground Truth Labels')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfV5Rx01QMhZ"
      },
      "source": [
        "# <font color='#4C5FDA'><small>**Preparaci칩n de los datos para el clasificador KNN**</small></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRKkTrBXrrdw"
      },
      "source": [
        "\n",
        "Ahora podemos importar nuestro conjunto de datos de im치genes a칠reas y convertirlo en un formato tabular para facilitar las operaciones de procesamiento sobre 칠l. En este caso, cada banda de imagen se convierte en una columna **(춰tenemos m치s de 100 bandas!)**, y se crea una columna de clase para almacenar los datos sobre nuestras etiquetas, con cada objeto clasificado posible representado como un n칰mero (en total 10). Luego se eliminan los elementos asociados con la clase 0, ya que la clase 0 se ha utilizado como una categor칤a general para todos los objetos no clasificados en la imagen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkb1JV_d3Q18",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# NO MODIFIQUES ESTA CELDA\n",
        "n_rows, n_cols, n_bands = img.shape  # Obtiene las dimensiones de la imagen: filas, columnas y bandas espectrales\n",
        "pixels = img.reshape((n_rows*n_cols, n_bands))  # Reorganiza la imagen en una matriz de p칤xeles (cada p칤xel con sus bandas espectrales)\n",
        "labels = gt.ravel()  # Aplana el array de etiquetas del terreno para que coincida con la estructura de los p칤xeles\n",
        "pixels, labels  # Muestra los arrays de p칤xeles y etiquetas\n",
        "\n",
        "pixels, labels = preprocess_data(img, gt)  # Preprocesa los datos de la imagen y las etiquetas del terreno\n",
        "# Filtra los p칤xeles que no tienen etiqueta en el terreno (etiquetas = 0)\n",
        "pixels = pixels[labels > 0]  # Selecciona solo los p칤xeles con etiquetas de terreno\n",
        "labels = labels[labels > 0]  # Selecciona solo las etiquetas correspondientes a esos p칤xeles\n",
        "\n",
        "# Divide el conjunto de datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(pixels, labels, test_size=0.3, random_state=42)  # Usa el 30% de los datos para prueba\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtzY30YoQwL-"
      },
      "source": [
        "# <font color='#ECA702'>**<font color=\"#FF0000\">R</font><font color=\"#FF7F00\">e</font><font color=\"#FFFF00\">t</font><font color=\"#00FF00\">o</font> #<font color=\"#0000FF\">1</font>** 游눩</font>\n",
        "* Construye el clasificador KNN, ayudate de la documentacion oficial en el siguiente enlace: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVGBL4l0yjkl",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Entrenar clasificador KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train,y_train)\n",
        "\n",
        "# Predecir en el conjunto de pruebas\n",
        "y_pred = knn.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMt3aD_wyjkl"
      },
      "outputs": [],
      "source": [
        "# Evaluacion\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Indice Jaccard: \", jaccard_score(y_test, y_pred, average='macro') )\n",
        "print(\"Reporte de clasificacion:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Matriz de Confusion:\")\n",
        "cf_matrix_knn = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cf_matrix_knn, annot=True, cmap=sns.cubehelix_palette(as_cmap=True), fmt='g')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntrjkfFcyjkl"
      },
      "source": [
        "# <font color='#4C5FDA'><small>**Entrenamiento del clasificador KNN usando todos los datos**</small></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcIA-6uOz7px"
      },
      "outputs": [],
      "source": [
        "# NO MODIFIQUES ESTA CELDA\n",
        "# Clasificar toda la imagen para su visualizaci칩n\n",
        "full_img_prediction = knn.predict(img.reshape((-1, img.shape[2])))\n",
        "pred_knn = full_img_prediction.reshape((img.shape[0], img.shape[1]))\n",
        "gt_flat = gt.ravel()\n",
        "mask = gt_flat != 0\n",
        "gt_filtered = gt_flat[mask]\n",
        "full_img_prediction_filtered = full_img_prediction[mask]\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(gt_filtered, full_img_prediction_filtered))\n",
        "print(\"Reporte de clasificacion:\")\n",
        "print(classification_report(gt_flat, full_img_prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yum5t43Wyjkm"
      },
      "source": [
        "# <font color='#4C5FDA'><small>**Graficar la prediccion del clasificador KNN**</small></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vTC42Ky6fMX"
      },
      "outputs": [],
      "source": [
        "# Trazar la imagen clasificada\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(pred_knn, cmap='jet')\n",
        "plt.title('Imagen clasificada con KNN')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(gt, cmap='jet')\n",
        "plt.title('Ground Truth')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGg7jQcRe9CN"
      },
      "source": [
        "# <font color='#4C5FDA'><small>**Preprocesamiento para el clasificador Decision Tree**</small></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMUVHE46UKld"
      },
      "outputs": [],
      "source": [
        "# NO MODIFIQUES ESTA CELDA\n",
        "\n",
        "df = pd.DataFrame(img.reshape(img.shape[0]*img.shape[1], -1))\n",
        "df.columns = [f'band{i}' for i in range(1, df.shape[-1]+1)]\n",
        "df['class'] = gt.ravel()\n",
        "df = df[df['class']!=0]\n",
        "\n",
        "stacked_bands = np.transpose(img, (2, 0, 1))\n",
        "sampled_bands = np.array([stacked_bands[0], stacked_bands[50], stacked_bands[100]])\n",
        "bands = [f'Band {i}' for i in range(1, 102, 50)]\n",
        "colors = list(mcolors.BASE_COLORS)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "epp.plot_rgb(\n",
        "    stacked_bands,\n",
        "    rgb=(60, 30, 27),\n",
        "    stretch=True,\n",
        "    figsize=(10, 10),\n",
        "    ax=plt.gca(),\n",
        ")\n",
        "plt.title('Imagen convertida')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(gt, cmap='jet')\n",
        "plt.title('Ground truth')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MyCigM-fQjw"
      },
      "source": [
        "# <font color='#ECA702'>**<font color=\"#FF0000\">R</font><font color=\"#FF7F00\">e</font><font color=\"#FFFF00\">t</font><font color=\"#00FF00\">o</font> #<font color=\"#0000FF\">2</font>** 游눩</font>\n",
        "* Construye el clasificador Decision Tree, ayudate de la documentacion oficial en el siguiente enlace: https://scikit-learn.org/stable/modules/tree.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCfXRMc-yjko"
      },
      "outputs": [],
      "source": [
        "# NO MODIFIQUES ESTA CELDA\n",
        "x = df.drop(['class'], axis=1)\n",
        "y = df['class']\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.7, stratify = y)\n",
        "y_encoder = le.fit(y_train)\n",
        "y_train = le.transform(y_train)\n",
        "y_test = le.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ab9Ynhp0yjko",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "model_dt = dt.fit(x_train.values, y_train)\n",
        "y_pred = model_dt.predict(x_test.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uuYUjokyjkp"
      },
      "outputs": [],
      "source": [
        "# Evaluacion\n",
        "print(\"Accuracy Score: \", round(accuracy_score(y_test, y_pred), 3)*100, \"%\")\n",
        "print(\"Indice Jaccard: \", jaccard_score(y_test, y_pred, average='macro'))\n",
        "print(\"Reporte de clasificacion:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "cf_matrix_dt = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cf_matrix_dt, annot=True, cmap=sns.cubehelix_palette(as_cmap=True), fmt='g')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_fYLleRyjkp"
      },
      "source": [
        "# <font color='#4C5FDA'><small>**Entrenamiento del clasificador Decision Tree**</small></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wxd_IykFEmyy"
      },
      "outputs": [],
      "source": [
        "l = []\n",
        "for i in range(img.shape[0]*img.shape[1]):\n",
        "    if i in list(df.index):\n",
        "        l.append(le.inverse_transform(model_dt.predict([df.loc[i, :][:-1]])))\n",
        "    else:\n",
        "        l.append(0)\n",
        "\n",
        "pred_dt = np.array(l, dtype=object).reshape(gt.shape).astype('float')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jcAd6ecyjkq"
      },
      "source": [
        "# <font color='#4C5FDA'><small>**Graficar la prediccion del clasificador Decision Tree**</small></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzvBrPI1MX3z"
      },
      "outputs": [],
      "source": [
        "# Trazar la imagen clasificada\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(pred_dt, cmap='jet')\n",
        "plt.title('Imagen clasificada con Decision Tree')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(gt, cmap='jet')\n",
        "plt.title('Ground Truth')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHufrtXaeUZ1"
      },
      "source": [
        "# <font color='#ECA702'>**<font color=\"#FF0000\">R</font><font color=\"#FF7F00\">e</font><font color=\"#FFFF00\">t</font><font color=\"#00FF00\">o</font> #<font color=\"#0000FF\">3</font>** 游눩</font>\n",
        "* Eval칰a el modelo de redes neuronales que implementamos para que visualices los resultados de esta clasificaci칩n.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JUZo0eqyjkq"
      },
      "source": [
        "# <font color='#4C5FDA'><small>**Declaracion del modelo**</small></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQNAqBCQD9_P"
      },
      "outputs": [],
      "source": [
        "# NO MODIFIQUES ESTA CELDA\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.cv1 = nn.Conv3d(1, 8, kernel_size=(3,3, 5))\n",
        "        self.cv2 = nn.Conv2d(8, 16, kernel_size=(3,3))\n",
        "        self.fc1 = nn.Linear(100048, 128)\n",
        "        self.dp = nn.Dropout(p=0.4)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.cv1(x)\n",
        "        out = F.relu(out)\n",
        "        out = torch.reshape(out, (out.shape[0], out.shape[1], out.shape[2], out.shape[3]*out.shape[4]))\n",
        "        out = self.cv2(out)\n",
        "        out = F.relu(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.dp(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVOnbIheGbbB"
      },
      "outputs": [],
      "source": [
        "def zeros_pad(x, margin):\n",
        "    padded_x = torch.zeros((x.shape[0] + 2 * margin, x.shape[1] + 2 * margin, x.shape[2]))\n",
        "    padded_x[margin:x.shape[0] + margin, margin:x.shape[1] + margin, :] = x\n",
        "    return padded_x\n",
        "\n",
        "def create_image(x, y, window_size):\n",
        "    margin = (window_size - 1) // 2\n",
        "    padded_x = zeros_pad(x, margin=margin)\n",
        "    patched_x = torch.zeros((x.shape[0] * x.shape[1], window_size, window_size, x.shape[2]))\n",
        "    patched_y = torch.zeros((x.shape[0] * x.shape[1]))\n",
        "    patch_index = 0\n",
        "    for i in range(margin, padded_x.shape[0] - margin):\n",
        "        for j in range(margin, padded_x.shape[1] - margin):\n",
        "            patch = padded_x[i - margin:i + margin + 1, j - margin:j + margin + 1]\n",
        "            patched_x[patch_index, :, :, :] = patch\n",
        "            patched_y[patch_index] = y[i-margin, j-margin]\n",
        "            patch_index += 1\n",
        "    patched_x = patched_x[patched_y>0,:,:,:]\n",
        "    patched_y = patched_y[patched_y>0]\n",
        "    patched_y -= 1\n",
        "    return patched_x, patched_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXaJI5Myyjk4"
      },
      "source": [
        "# <font color='#4C5FDA'><small>**Cargamos los modelos necesarios**</small></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzPQE9u3Ce7S"
      },
      "outputs": [],
      "source": [
        "# NO MODIFIQUES ESTA CELDA\n",
        "\n",
        "# Cargar el modelo de Deep Learning completo\n",
        "model = torch.load('complete_model.pth', weights_only=False)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47X1RFA-EI5f"
      },
      "outputs": [],
      "source": [
        "# NO MODIFIQUES ESTA CELDA\n",
        "\n",
        "# Cargar el modelo PCA\n",
        "pca = joblib.load('model_pca.pkl')\n",
        "\n",
        "# Cargar los conjuntos de datos particionados\n",
        "cnn_x_train = torch.load('cnn_x_train.pth')\n",
        "cnn_x_test = torch.load('cnn_x_test.pth')\n",
        "cnn_y_train = torch.load('cnn_y_train.pth')\n",
        "cnn_y_test = torch.load('cnn_y_test.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llyRmDCsGCjh"
      },
      "outputs": [],
      "source": [
        "# NO MODIFIQUES ESTA CELDA\n",
        "\n",
        "dimensions = 17\n",
        "window_size = 25\n",
        "test_perc = 0.3\n",
        "\n",
        "# Aqu칤 realizamos la creaci칩n de DataLoader para la evaluaci칩n\n",
        "# No necesitas aplicar PCA de nuevo, ya que los datos ya est치n transformados y listos para usarse\n",
        "test = torch.utils.data.TensorDataset(cnn_x_test, cnn_y_test)\n",
        "testloader = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mguWx3dyjk6"
      },
      "source": [
        "# <font color='#4C5FDA'><small>**Ejecuta las siguientes 2 celdas para evaluar el modelo pre-entrenado**</small></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YZxzdGro1QA"
      },
      "outputs": [],
      "source": [
        "# NO MODIFIQUES ESTA CELDA\n",
        "def confusion_matrix(data, nb_classes):\n",
        "    df_cm = pd.DataFrame(data,\n",
        "                          range(nb_classes), range(nb_classes))\n",
        "    plt.figure(figsize=(10,7))\n",
        "    sns.set(font_scale=1.4) # for label size\n",
        "    sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16},cmap='Blues',\n",
        "                fmt='g')\n",
        "    plt.title(\"Confusion Matrix\", fontsize = 20)\n",
        "    plt.xlabel(\"Predicted Output\", fontsize = 18)\n",
        "    plt.ylabel(\"Expected Output\", fontsize = 18)\n",
        "    plt.show()\n",
        "\n",
        "def acc_per_class(model, testloader, nb_classes):\n",
        "    model.eval()\n",
        "    confusion_mat = torch.zeros(nb_classes, nb_classes)\n",
        "    class_correct = torch.zeros(10)\n",
        "    class_total = torch.zeros(10)\n",
        "    total = 0\n",
        "    for inputs, labels in testloader:\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(labels.view(-1), preds.view(-1)):\n",
        "            confusion_mat[t.long(), p.long()] += 1\n",
        "\n",
        "    confusion_matrix(confusion_mat.data.cpu().numpy(), nb_classes)\n",
        "\n",
        "    per_class_acc = 100*confusion_mat.diag()/confusion_mat.sum(1)\n",
        "    for i, j in enumerate(per_class_acc.data.cpu().numpy()):\n",
        "        print(\"Class:\", i, \"Accuracy:\", j)\n",
        "    acc = torch.mean(per_class_acc).data.cpu().numpy()\n",
        "    print(\"Overall Accuracy: \", acc, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fppjd0fuo24X"
      },
      "outputs": [],
      "source": [
        "# NO MODIFIQUES ESTA CELDA\n",
        "x = np.reshape(img, (-1, img.shape[2]))\n",
        "x_pca = pca.fit_transform(x)\n",
        "x_pca = np.reshape(x_pca, (img.shape[0], img.shape[1], dimensions))\n",
        "padded_x = zeros_pad(torch.tensor(x_pca), window_size//2)\n",
        "\n",
        "pred = np.zeros((gt.shape[0], gt.shape[1]))\n",
        "for h in range(gt.shape[0]):\n",
        "    for w in range(gt.shape[1]):\n",
        "        if int(gt[h, w]) == 0:\n",
        "            continue\n",
        "        else:\n",
        "            model.eval()\n",
        "            image_patch = padded_x[h:h+window_size, w:w+window_size, :]\n",
        "            image = torch.permute(image_patch[None, None, :, :, :], (0, 1, 4, 2, 3))\n",
        "            pred[h][w] = model(image).argmax(dim=1) + 1\n",
        "\n",
        "acc_per_class(model, testloader, 9)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-R8wSRSUyjk7"
      },
      "source": [
        "# <font color='#4C5FDA'><small>**Ejecuta la siguiente celda para obtener el 칈ndice de Jaccard**</small></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWKxj31Fc5g-"
      },
      "outputs": [],
      "source": [
        "# NO MODIFIQUES ESTA CELDA\n",
        "def jaccard_coefficient(pred, gt, nb_classes):\n",
        "    jaccard_per_class = np.zeros(nb_classes)\n",
        "    for cls in range(1, nb_classes + 1):  # Class labels start from 1\n",
        "        pred_cls = pred == cls\n",
        "        gt_cls = gt == cls\n",
        "        intersection = np.logical_and(pred_cls, gt_cls).sum()\n",
        "        union = np.logical_or(pred_cls, gt_cls).sum()\n",
        "        if union == 0:\n",
        "            jaccard_per_class[cls - 1] = np.nan  # To handle division by zero\n",
        "        else:\n",
        "            jaccard_per_class[cls - 1] = intersection / union\n",
        "    return np.nanmean(jaccard_per_class), jaccard_per_class  # Return average and per-class Jaccard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2OECBWMKI_j"
      },
      "outputs": [],
      "source": [
        "# NO MODIFIQUES ESTA CELDA\n",
        "nb_classes = 9  # N칰mero de clases\n",
        "avg_jaccard, jaccard_per_class = jaccard_coefficient(pred, gt, nb_classes)\n",
        "print(\"Average Jaccard Coefficient:\", avg_jaccard)\n",
        "print(\"Jaccard Coefficient per Class:\", jaccard_per_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDPRYvKnyjk8"
      },
      "source": [
        "# <font color='#4C5FDA'><small>**Graficar la prediccion del clasificador con Deep Learning**</small></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWO4LB4b53wg"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(pred, cmap='jet')\n",
        "plt.title('Imagen clasificada con Deep Learning')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(gt, cmap='jet')\n",
        "plt.title('Ground Truth')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwF7sTjO6ICn"
      },
      "source": [
        "# **<font color=\"#FF0000\">E</font><font color=\"#FF7F00\">x</font><font color=\"#FFFF00\">t</font><font color=\"#00FF00\">r</font><font color=\"#0000FF\">a</font>**: Grafica los tres resultados de los tres clasificadores y compara los resultados de manera visual. 쮺ual crees que es el mejor clasificador y por qu칠?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sE0Fko7B6knD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "outputId": "df934c30-c701-4bee-ccde-4ae9b568b468"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pred_knn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-435a54ea14db>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_knn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'jet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'KNN Classification'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pred_knn' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.imshow(pred_knn, cmap='jet')\n",
        "plt.title('KNN Classification')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 4, 2)\n",
        "plt.imshow(pred_dt, cmap='jet')\n",
        "plt.title('Decision Tree Classification')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.imshow(pred, cmap='jet')\n",
        "plt.title('Deep Learning Classification')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 4, 4)\n",
        "plt.imshow(gt, cmap='jet')\n",
        "plt.title('Ground Truth')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}